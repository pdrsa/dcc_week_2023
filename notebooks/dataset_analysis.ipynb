{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275f8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import pearsonr\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class ECG_Dataset(Dataset):\n",
    "    def __init__(self, \n",
    "                tracings_file_path,\n",
    "                labels_file_path,\n",
    "                start = 0,\n",
    "                end = -1):\n",
    "        self.f = h5py.File(tracings_file_path, 'r')\n",
    "\n",
    "        # Get tracings\n",
    "        self.trace_ids = np.array(self.f['exam_id'])[start:end]\n",
    "        self.tracings = self.f['tracings']\n",
    "\n",
    "        # Defining start and end\n",
    "        self.start = start\n",
    "        self.end   = (end if end != -1 else len(self.tracings)-1)\n",
    "\n",
    "        # Get labels\n",
    "        labels_df = pd.read_csv(labels_file_path)\n",
    "        self.labels    = {labels_df[\"exam_id\"][i]:labels_df[\"classe\"][i] for i in range(len(self.tracings))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.end - self.start\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get tracing\n",
    "        tracing_idx = self.start + idx\n",
    "        tracing = np.transpose(self.tracings[tracing_idx])\n",
    "        \n",
    "        # Get label\n",
    "        label = self.labels[self.trace_ids[idx]]\n",
    "\n",
    "        return tracing, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5206626",
   "metadata": {},
   "source": [
    "In the next cell I try to apply a tucker decomposition, witch is (or should be) a SVD equivalent but for tensors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be1f60",
   "metadata": {},
   "source": [
    "```\n",
    "from tensorly.decomposition import tucker\n",
    "import tensorly as tl\n",
    "\n",
    "with h5py.File('../data/train_dccweek2023.h5', 'r') as f:\n",
    "    X = f['tracings'][:5000]\n",
    "    \n",
    "\n",
    "# aplica o HOSVD mantendo a primeira dimensão\n",
    "factors = tucker(X, rank=[5000, 2000, 2])\n",
    "\n",
    "# reconstrói o tensor original usando os componentes principais\n",
    "X_hosvd = tl.kruskal_to_tensor(factors)\n",
    "\n",
    "# verifica as dimensões do novo tensor\n",
    "print(X_hosvd.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ed651f",
   "metadata": {},
   "source": [
    "The above cell uses just way too much memory and takes an eternity to run, and since it is 10x smaller than the full dataset and it needs to be loaded all at once, it cant be a good solution.\n",
    "\n",
    "The next test should be to iter over each sample individualy, and reduce its dimension using PCA from (1, 4096, 12) to (1, 4096, 2) and build a new training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a01fb89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = ECG_Dataset('../data/train_dccweek2023.h5',\n",
    "                      '../data/train_dccweek2023-labels.csv',\n",
    "                      start = 0, end = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a88fbcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"tracings\": shape (51432, 4096, 12), type \"<f4\">"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tracings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eef32874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG_Dataset_Features(ECG_Dataset):\n",
    "    def __getitem__(self, idx):\n",
    "        # Get tracing\n",
    "        tracing_idx = self.start + idx\n",
    "        tracing = self.tracings[tracing_idx]\n",
    "        \n",
    "        # Adding pca of each signal to features\n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(tracing)\n",
    "        transformed = np.transpose(pca.transform(tracing))\n",
    "        \n",
    "        # Adding fft analysis\n",
    "        harmonics = []\n",
    "        for signal in np.transpose(tracing):\n",
    "            dft = np.fft.fft(signal)\n",
    "            spectrum = np.abs(dft)\n",
    "            T = 1/4096\n",
    "            N = 4096\n",
    "            f = np.fft.fftfreq(N, T)\n",
    "            frequencias = f[:N // 2]\n",
    "            amplitudes = np.abs(dft)[:N // 2] * 1 / N\n",
    "            best_5 = sorted(zip(amplitudes, frequencias), key = lambda x: x[0])[-1:-6:-1]\n",
    "            harmonics.append(best_5)\n",
    "        \n",
    "        label = self.labels[self.trace_ids[idx]]\n",
    "\n",
    "        return transformed, harmonics, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "820b899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dataset = ECG_Dataset_Features('../data/train_dccweek2023.h5',\n",
    "                      '../data/train_dccweek2023-labels.csv',\n",
    "                      start = 0, end = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a9c3bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00132167,  0.00132167,  0.00132167, ...,  0.00132167,\n",
       "          0.00132167,  0.00132167],\n",
       "        [-0.00620164, -0.00620164, -0.00620164, ..., -0.00620164,\n",
       "         -0.00620164, -0.00620164]], dtype=float32),\n",
       " [[(0.05926092171471409, 38.0),\n",
       "   (0.0555799393403267, 9.0),\n",
       "   (0.05307683713648391, 66.0),\n",
       "   (0.050414289030029355, 10.0),\n",
       "   (0.047854997983364136, 28.0)],\n",
       "  [(0.0367439150385997, 66.0),\n",
       "   (0.033473448714124755, 28.0),\n",
       "   (0.031255772613225145, 38.0),\n",
       "   (0.02823140027741715, 94.0),\n",
       "   (0.027913665965537095, 75.0)],\n",
       "  [(0.03552166047944737, 9.0),\n",
       "   (0.03174460508353783, 10.0),\n",
       "   (0.029807461527912756, 47.0),\n",
       "   (0.029384758734274895, 38.0),\n",
       "   (0.026231576642047612, 75.0)],\n",
       "  [(0.04507922339990268, 38.0),\n",
       "   (0.043990256763507866, 66.0),\n",
       "   (0.040123084905469855, 28.0),\n",
       "   (0.03835756876954246, 9.0),\n",
       "   (0.03497336015732579, 10.0)],\n",
       "  [(0.04534351443579583, 9.0),\n",
       "   (0.04406721131937605, 38.0),\n",
       "   (0.040926224167188316, 10.0),\n",
       "   (0.036991263446432644, 66.0),\n",
       "   (0.036574219496958014, 47.0)],\n",
       "  [(0.01875857545770519, 85.0),\n",
       "   (0.017240500584215685, 94.0),\n",
       "   (0.01690230167160649, 113.0),\n",
       "   (0.01632129146465202, 66.0),\n",
       "   (0.015630796787072118, 104.0)],\n",
       "  [(0.024590722918442484, 132.0),\n",
       "   (0.023363856689499307, 28.0),\n",
       "   (0.02329821501606652, 104.0),\n",
       "   (0.02268669305243409, 66.0),\n",
       "   (0.022542425517892897, 151.0)],\n",
       "  [(0.062097926266585404, 9.0),\n",
       "   (0.054525037381908316, 10.0),\n",
       "   (0.027710901188811733, 38.0),\n",
       "   (0.02343942601264395, 19.0),\n",
       "   (0.021566044573464425, 47.0)],\n",
       "  [(0.10341561127861963, 9.0),\n",
       "   (0.09223675108793383, 10.0),\n",
       "   (0.07008832572199196, 38.0),\n",
       "   (0.062101119186731106, 66.0),\n",
       "   (0.051868905597952084, 37.0)],\n",
       "  [(0.08814627377380566, 9.0),\n",
       "   (0.07827259045050498, 10.0),\n",
       "   (0.07637956803487496, 38.0),\n",
       "   (0.0737299508723998, 66.0),\n",
       "   (0.06051416981090948, 28.0)],\n",
       "  [(0.10061331730107324, 38.0),\n",
       "   (0.09563146257546717, 66.0),\n",
       "   (0.09227923283045392, 9.0),\n",
       "   (0.08505143826873209, 28.0),\n",
       "   (0.08122450564758296, 10.0)],\n",
       "  [(0.08975451737316163, 38.0),\n",
       "   (0.08405461921984105, 66.0),\n",
       "   (0.07641290554879498, 28.0),\n",
       "   (0.07479900125121794, 9.0),\n",
       "   (0.06839976954565369, 10.0)]],\n",
       " 0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5ba4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
